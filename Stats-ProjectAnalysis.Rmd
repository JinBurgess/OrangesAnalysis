

```{r}
library(readr)
df <- read_csv('./OrangeQualityAnalysis/data/OrangeQualityData.csv')
```
```{r}
library(dplyr)
library(stringr)

colnames(df) <- c("Size", "Weight", "Sweetness",
                  "Acidity", "Softness", "HarvestTime", 
                  "Ripeness", "Color", "Variety", 
                  "Blemishes", "Quality")
df1 <- df %>%
  mutate(Blemishes = if_else(str_detect(Blemishes, 'Y'), "Y", "N"))%>%
  select(-Variety)

# df1 <- df %>%
#   mutate(`Blemishes (Y/N)` = if_else(str_detect(`Blemishes (Y/N)`, 'Y'), 1, 0))
# 1 = Yes blemish
# 0 = No blemish
```

Categorical-Categorical
***********************************************************
contingency table
```{r}
my.chisq.test <- function(conting.table) {
  # Calculate sums of rows and columns
  # https://www.geeksforgeeks.org/mutating-column-in-dplyr-using-rowsums/
  row.sums <- rowSums(conting.table)
  col.sums <- colSums(conting.table)
  total.sum <- sum(conting.table)
  
  # Calculate expected cell counts
  # Eij = (ni * n.j)/n
  # https://www.geeksforgeeks.org/outer-function-in-r/
  expected <- outer(row.sums, col.sums) / total.sum
  
  # x^2 = E(observed - expected)^2/expected
  # observed = continegency table 
  chisq <- sum((conting.table - expected)^2 / expected)
  
  # Calculate degrees of freedom
  deg.free <- (nrow(conting.table) - 1) * (ncol(conting.table) - 1)
  
  # Calculate p-value
  p.value <- 1 - pchisq(chisq, df = deg.free)
  
  return(list(chi2 = chisq, p_value = p.value, df = deg.free))
}
```


```{r}
df_cateogrical <- df1 %>%
  select(Blemishes, Color)
```


```{r}
blemish_color_table <- table(df_cateogrical$Color, df_cateogrical$Blemishes)
my.chisq.test(blemish_color_table)
```
H0: Color is independent of Blemishes
Ha: Color is dependent of Blemishes

Fail to reject H0

```{r}
#create density curve
curve(dchisq(x, df = 4), from = 0, to = 25,
main = 'Chi-Square Distribution (df = 4)',
ylab = 'Density',
lwd = 2)

#create vector of x values
x_vector <- seq(5.86, 25)

#create vector of chi-square density values
p_vector <- dchisq(x_vector, df = 4)

#fill in portion of the density plot from 0 to 40
polygon(c(x_vector, rev(x_vector)), c(p_vector, rep(0, length(p_vector))),
        col = adjustcolor('blue', alpha=0.3), border = NA)

abline(v = 4, col = "red", lwd = 3)
```


```{r}
blemish_color_table
```

```{r}
  row.sums <- rowSums(blemish_color_table)
  col.sums <- colSums(blemish_color_table)
  total.sum <- sum(blemish_color_table)
  
  # Calculate expected cell counts
  # Eij = (ni * n.j)/n
  # https://www.geeksforgeeks.org/outer-function-in-r/
  expected <- outer(row.sums, col.sums) / total.sum
  
  round(expected, 2)
```

$$
\frac{\text{(Observed - Expected)}^2}{\text{Expected}}
$$

```{r}
chisq <- ((blemish_color_table - expected)^2 / expected)
round(chisq, 3)
```

```{r}
library(ggplot2)

blemish_color_df <- as.data.frame(blemish_color_table)%>% 
  mutate(prop = round(Freq/sum(Freq),2))

colnames(blemish_color_df) <- c("Color", "Blemishes", "Frequency", "Proportion")

```

```{r}
blemish_color_df%>%
  ggplot(aes(x = Blemishes, y = Proportion, fill = Blemishes))+
  geom_col() + facet_wrap(~Color) + guides(fill = "none") + theme_minimal() +
  theme(axis.line.y = element_blank())
```

$$
H_0 : \text{Orange color is independent of blemish presence} \\
H_a : \text{Orange color is dependent of blemish presence}
$$

Multi-Linear Regression
***********************************************************

Correlation Matrix
```{r}
library(tidyverse)
library(caret)
df_matrix <- df1 %>%
    select_if(is.numeric) %>%
    cor(.)
round(df_matrix,2)
```
VIF
```{r}
library(car)
vif(lm(Sweetness ~ ., data = df1))
```

Written Equations
***********************************************************
$$
Sweetness_i \sim \beta_0 + \beta_1 X_{\text{size i}} + \beta_2 X_{\text{weight i}} + \beta_3 X_{\text{Acidity i}} + 
\beta_4 X_{\text{Softness i}} + \beta_5 X_{\text{HarvestTime i}} + \\
\beta_6 X_{\text{ripness i}} + \beta_7 D_{\text{Color.LightOrange i}} + \beta_8 D_{\text{Color.Orange i}} +
\beta_9 D_{\text{Color.OrangeRed i}} + \\
\beta_{10} D_{\text{Color.YellowOrange i}} + 
\beta_{11} D_{\text{BlemishesY i}}+ \beta_{12} X_{\text{Quallity i}} + \epsilon_i, \epsilon_i \sim_{\text{iid}} N(0, \sigma^2) \\
$$

$$
\text{Baseline: color is deep orange}\\
D_{\text{Color.LightOrange i}} = \{ \text{1, if color is light orange otherwise, 0}\} \\
D_{\text{Color.Orange i}} = \{ \text{1, if color is orange otherwise, 0}\}\\
D_{\text{Color.OrangeRed i}} = \{ \text{1, if color is orange red otherwise, 0}\}\\
D_{\text{Color.YellowOrange i}} = \{ \text{1, if color is yellow orange otherwise, 0}\}\\
$$
$$
\text{Baseline: blemishes is No}\\
D_{\text{BlemishesY i}} = \{ \text{1, if blemishes is Yes otherwise, 0}\}
$$

Multiple Linear Regression
***********************************************************
```{r}
lm.obj <- lm(Sweetness ~ ., data = df1)
summary(lm.obj)
```

AIC
***********************************************************
```{r}
df2 <- df1%>%
  select(Size, Acidity, Softness, Quality, Color, Sweetness)

lm.obj <- lm(Sweetness ~., data = df2)
step(lm.obj)
```


Full modeling
$$
Sweetness_i \sim \beta_0 + \beta_1 X_{\text{size i}} + \beta_2 X_{\text{Acidity i}} + \beta_3 X_{\text{Softness i}} + \\
\beta_4 X_{\text{Quality i}} + \beta_5 D_{\text{Color.LightOrange i}} + \beta_6 D_{\text{Color.Orange i}} + \\
\beta_7 D_{\text{Color.OrangeRed i}} + \beta_8 D_{\text{Color.YellowOrange i}} + \epsilon_i, \epsilon_i \sim_{\text{iid}} N(0, \sigma^2) \\
$$
Fitted
$$
\hat{Sweetness} = 17.629- 0.467(Size) -0.804(Acidity) - 0.313 (Softness) + 0.872(Quality) \\
-2.806(D_{\text{Color.LightOrange}}) -1.806(D_{\text{Color.Orange}}) -
0.982 (D_{\text{Color.OrangeRed}}) -3.331 (D_{\text{Color.YellowOrange}})
$$

Incremental F-test of Categorical Variable
***********************************************************
$$
H_0: \beta_5 = \beta_6 = \beta_7 = \beta_8 = 0; H_a: \beta_j \neq 0 \text{, {j = 5,6,7, or 8}}
$$

```{r}
lm.full.obj <- lm(Sweetness ~., data = df2)
lm.null.obj <- lm(Sweetness ~. - Color, data = df2)
anova(lm.null.obj, lm.full.obj)
```


Interaction Term
***********************************************************
```{r}
ggplot(data=df1, aes(Size, Sweetness, col=Color)) + 
  geom_smooth(method="lm", se = FALSE) + theme_minimal()

ggplot(data=df1, aes(Acidity, Sweetness, col=Color)) + 
  geom_smooth(method="lm", se = FALSE) + theme_minimal()

ggplot(data=df1, aes(Softness, Sweetness, col=Color)) + 
  geom_smooth(method="lm", se = FALSE) + theme_minimal()

ggplot(data=df1, aes(Quality, Sweetness, col=Color)) + 
  geom_smooth(method="lm", se = FALSE) + theme_minimal()
```

SIZE
```{r}
lm.obj <- lm(Sweetness ~ Acidity + Softness + Quality + 
     Size*Color, data = df2)

summary(lm.obj)
```

```{r}
lm.obj <- lm(Sweetness ~ Acidity + Softness + Quality + 
     Size*Color, data = df2)

null.obj <- lm(Sweetness ~., data = df2)

anova(null.obj, lm.obj)
```

SOFTNESS

```{r}
lm.obj <- lm(Sweetness ~ Size + Quality + Acidity + 
     Softness*Color, data = df2)

summary(lm.obj)
```

```{r}
lm.obj <- lm(Sweetness ~ Size + Quality + Acidity + 
     Softness*Color, data = df2)

null.obj <- lm(Sweetness ~., data = df2)

anova(null.obj, lm.obj)
```

ACIDITY

```{r}
lm.obj <- lm(Sweetness ~ Size + Quality + Softness + 
     Acidity*Color, data = df2)

summary(lm.obj)
```

```{r}
lm.obj <- lm(Sweetness ~ Size + Quality + Softness + 
     Acidity*Color, data = df2)
null.obj <- lm(Sweetness ~., data = df2)

anova(null.obj, lm.obj)
```

Incremental F-test of Categorical Variable
***********************************************************
$$
H_0: \beta_9 = \beta_{10} = \beta_{11} = \beta_8 = {12}; H_a: \beta_j \neq 0 \text{, {j = 9, 10, 11, or 12}}
$$

QUALITY
```{r}
lm.obj <- lm(Sweetness ~ Size + Softness + Acidity + 
     Quality*Color, data = df2)

summary(lm.obj)
```


```{r}
lm.obj <- lm(Sweetness ~ Size + Softness + Acidity + 
     Quality*Color, data = df2)

null.obj <- lm(Sweetness ~., data = df2)

anova(null.obj, lm.obj)
```

Full modeling
$$
Sweetness_i \sim \beta_0 + \beta_1 X_{\text{size i}} + \beta_2 X_{\text{Acidity i}} + \beta_3 X_{\text{Softness i}} + \beta_4 X_{\text{Quality i}} + \\ \beta_5 D_{\text{Color.LightOrange i}} + \beta_6 D_{\text{Color.Orange i}} + \beta_7 D_{\text{Color.OrangeRed i}} + \beta_8 D_{\text{Color.YellowOrange i}} + \\ \beta_9 (Quality \cdot D_\text{Color.Light Orange})_i + \beta_{10} (Quality \cdot  D_\text{Color.Orange})_i + \beta_{11} (Quality \cdot D_\text{Color.Orange-Red})_i + \\
\beta_{12} (Quality \cdot D_\text{Color.Yellow-Orange})_i + 
\epsilon_i, \epsilon_i \sim_{\text{iid}} N(0, \sigma^2) \\
$$

Fitted Equation
$$
\hat{\text{Sweetness}}
= 21.0965 - (0.3312)\text{Size} - (0.3925)\text{Softness} - (0.8338)\text{Acidity} - (0.3894)\text{Quality} - \\
(9.2542) D_\text{Color.Light Orange} - (7.0292) D_\text{Color.Orange} - (10.2022) D_\text{Color.Orange-Red} - (4.4549) D_\text{Color.Yellow-Orange} + \\
(1.5896)Quality \cdot D_\text{Color.Light Orange}+ (1.1848)Quality \cdot D_\text{Color.Orange} + \\
(2.2407)Quality \cdot D_\text{Color.Orange-Red} +
(0.3385)Quality \cdot D_\text{Color.Yellow-Orange}
$$


Diagnostic Plots
***********************************************************

```{r}
lm.obj <- lm(Sweetness ~ Size + Softness + Acidity + 
     Quality*Color, data = df2)

plot(lm.obj)
```

```{r}
lm.obj <- lm(log(Sweetness)~ Size + Softness + Acidity + 
     Quality*Color, data = df2)

plot(lm.obj, which = 2)
```

```{r}
lm.obj <- lm(sqrt(Sweetness)~ Size + Softness + Acidity + 
     Quality*Color, data = df2)

plot(lm.obj, which = 2)
```


```{r}
plot(hatvalues(lm.obj))
text(x=1:nrow(df2),
     y=hatvalues(lm.obj),
     rownames(df2),
     cex=0.6, pos=4, col="red")
```
```{r}
plot(lm.obj, which=4)
```

Influential Observations
***********************************************************

```{r}
cat("RSE:", sigma(lm.obj), "\n")
cat("RË†2:", summary(lm.obj)$r.squared, "\n")
```

```{r}
advertising_minus_137 <- df2[-137, ]

lm.obj_reduced <- lm(Sweetness ~ Size + Softness + Acidity + 
     Quality*Color, data = advertising_minus_137)

cat("RSE:", sigma(lm.obj_reduced), "\n")
cat("RË†2:", summary(lm.obj_reduced)$r.squared, "\n")
```

Confidence Interval
```{r}
confint(lm.obj)
```

Multiple Logistic Regression
***********************************************************
**What ar we considering our cut off for splitting?**

Variable Selection
- looks at VIF for variable selection

```{r}
library(car)
df1 <- df %>%
  mutate(Blemishes = if_else(str_detect(Blemishes, 'Y'), 1, 0))%>%
  select(-Variety)

vif(glm(Blemishes ~ ., data = df1))
```

Run incremental F-test to see if model is significant with Color (using similar process from linear just assumming it can be applied)

```{r}
glm.full.obj <- glm(Blemishes ~., data = df1)
glm.null.obj <- glm(Blemishes ~. - Color, data = df1)
anova(lm.null.obj, lm.full.obj)
```

```{r}
glm.multiple <- glm(Blemishes ~ ., 
               data = df1, 
               family="binomial")

summary(glm.multiple)
```

simplfying model to those that are significant

```{r}
df2 <- df1%>%
  select(Blemishes, Acidity, Ripeness, Size)

glm.multiple <- glm(Blemishes ~ ., 
               data = df2, 
               family="binomial")

summary(glm.multiple)
```

$$
Y_i \sim _\text{indep} Bin (1, p_i), p_i = P(Y = 1 | Acidity_i, Ripeness_i)\\
log(\frac{p(X)}{1 - p(X)}) = \beta_0 + \beta_1(Acidity_i) + \beta_2(Ripeness_i)
$$


```{r}
df2 <- df2%>%
  select(-Size)
glm.multiple <- glm(Blemishes ~ .,
                    data=df2,
                    family="binomial")
glm.multiple

summary(glm.multiple)
```


$$
\text{Fitted Equation}: log(\frac{\hat{p(X)}}{1 - \hat{p(X)}}) = \\
-3.1305 + (1.2494)\text{Acidity} - (0.5015) \text{Ripeness}
$$
Analysis of Deviance / Likelihood-Ratio Test
for significance of full model/subset of predictors)
```{r}
glm.multiple <- glm(Blemishes ~ .,
                    data=df2,
                    family="binomial")

glm.null <- glm(Blemishes ~ 1,
                data=df2,
                family="binomial")

# Test for significance of the full model:
anova(glm.null, glm.multiple, test = "LRT")
```


Confidence Interval

```{r}
confint(glm.multiple, level = 0.95)
```

```{r}
glm.multiple <- glm(Blemishes ~ .,
                    data=df2,
                    family="binomial")
glm.multiple
# Probability predictions:
predict(glm.multiple, newdata=data.frame(Acidity = 1, Ripeness = 3.5),
        type='response')

```
```{r}
acidity2 <- nrow(df2[df2$Acidity == 3, ])
acidity2/ nrow(df2[df2$Blemishes == 1, ])
```

